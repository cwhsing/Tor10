

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tor10.UniTensor &mdash; Tor10 0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> Tor10
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Bond.html">Tor10.Bond</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../UniTensor.html">Tor10.UniTensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Network.html">Tor10.Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">Tor10.linalg</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Tor10</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>Tor10.UniTensor</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for Tor10.UniTensor</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">copy</span><span class="o">,</span><span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pickle</span> <span class="k">as</span> <span class="nn">pkl</span>
<span class="kn">from</span> <span class="nn">.Bond</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">linalg</span> 

<span class="c1">## Developer Note:</span>
<span class="c1">## [KHW]</span>
<span class="c1">## Currently trying to add the Symm. </span>
<span class="c1">## A temporary Abort is use to prevent the user to call the un-support operations on a Symmetry tensor. </span>
<span class="c1">##</span>
<span class="c1">##  Find &quot;Qnum_ipoint&quot; keyword for the part that need to be modify accrodingly when considering the Qnums feature. </span>
<span class="c1">##</span>

<div class="viewcode-block" id="UniTensor"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor">[docs]</a><span class="k">class</span> <span class="nc">UniTensor</span><span class="p">():</span>

<div class="viewcode-block" id="UniTensor.__init__"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bonds</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span><span class="n">torch_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">is_diag</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is the constructor of the UniTensor.</span>

<span class="sd">        Public Args:</span>

<span class="sd">            bonds: </span>
<span class="sd">                The list of bonds. it should be an list or np.ndarray with len(list) is the # of bonds.  </span>

<span class="sd">            labels: </span>
<span class="sd">                The label of each bond. </span>
<span class="sd">                1. the number of elements should be the same as the total rank of the tensor, contain no duplicated elements.</span>
<span class="sd">                2. all the label should be integer. if the label is specify as floating point, it will be rounded as integer. </span>

<span class="sd">            device: </span>
<span class="sd">                This should be a [torch.device]. When provided, the tensor will be put on the device (&quot;cpu&quot;, &quot;cuda&quot;, &quot;cuda:x&quot; with x is the GPU-id. See torch.device for further information.)</span>
<span class="sd">            </span>
<span class="sd">            dtype : </span>
<span class="sd">                This should be a [ torch.dtype ]. </span>
<span class="sd">                *The default type is float with either float32 or float64 which follows the same internal rule of pytorch. For further information, see pytorch documentation. </span>
<span class="sd">            </span>
<span class="sd">            is_diag: </span>
<span class="sd">                This states if the current UniTensor is a diagonal matrix or not. If True, the Storage will only store diagonal elements.</span>
<span class="sd">                Note that if is_diag=True, then the UniTensor is strictly required to be a square 2-rank tensor.  </span>
<span class="sd">            requires_grad:</span>
<span class="sd">                Activate the autograd function for UniTensor. This is the same as torch.Tensor </span>
<span class="sd">                </span>
<span class="sd">            name: </span>
<span class="sd">                This states the name of current UniTensor.      </span>

<span class="sd">        Private Args:</span>
<span class="sd">        </span>

<span class="sd">           ** [Warning] Private Args should not be call directly **</span>


<span class="sd">            torch_tensor : </span>
<span class="sd">                This is the internal arguments in current version. It should not be directly use, otherwise may cause inconsistence with Bonds and memory layout. </span>
<span class="sd">                    *For Developer:</span>
<span class="sd">                        &gt; The torch_tensor should have the same rank as len(label), and with each bond dimensions strictly the same as describe as in bond in self.bonds.</span>

<span class="sd">            check : </span>
<span class="sd">                This is the internal arguments. It should not be directly use. If False, all the checking across bonds/labels/Storage.shape will be ignore. </span>
<span class="sd">        </span>

<span class="sd">        Example for how to create a UniTensor:</span>
<span class="sd">        </span>
<span class="sd">            * create a 2-rank UniTensor (matrix) with shape (3,4): </span>
<span class="sd">            &gt;&gt;&gt; a = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4)])</span>

<span class="sd">            * create a 3-rank UniTensor with shape (3,4,5) and set labels [-3,4,1] for each bond:</span>
<span class="sd">            &gt;&gt;&gt; c = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4),Tor10.Bond(Tor10.BD_OUT,5)],labels=[-3,4,1])</span>

<span class="sd">            * create a 2-rank UniTensor with shape (3,4) on GPU-0:</span>
<span class="sd">            &gt;&gt;&gt; d = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4)],device=torch.device(&quot;cuda:0&quot;))</span>

<span class="sd">            * create a diagonal 6x6 2-rank tensor(matrix):</span>
<span class="sd">            &gt;&gt;&gt; e = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,6),Tor10.Bond(Tor10.BD_OUT,6)],is_diag=True)</span>
<span class="sd">            </span>
<span class="sd">            Note that when is_diag is set to True, the UniTensor should be a square matrix.</span>

<span class="sd">            * crate a 3-rank UniTensor with single precision:</span>
<span class="sd">            &gt;&gt;&gt; f = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4),Tor10.Bond(Tor10.BD_OUT,5)],labels=[-3,4,1],dtype=torch.float32)</span>
<span class="sd">            </span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">bonds</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="o">=</span> <span class="n">is_diag</span>        

        
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
        
        <span class="c1">## Checking:</span>
        <span class="k">if</span> <span class="n">check</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.__init__&quot;</span><span class="p">,</span><span class="s2">&quot;labels size is not consistence with the rank&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.__init__&quot;</span><span class="p">,</span><span class="s2">&quot;labels contain duplicate element.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">is_diag</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.__init__&quot;</span><span class="p">,</span><span class="s2">&quot;is_diag=True require Tensor rank==2&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.__init__&quot;</span><span class="p">,</span><span class="s2">&quot;is_diag=True require Tensor to be square rank-2&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">([</span> <span class="p">(</span><span class="n">bd</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">]))</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.__init__&quot;</span><span class="p">,</span><span class="s2">&quot;the bonds are not consistent. Cannot have mixing bonds of with and without symmetry (qnums).&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">([</span> <span class="n">bd</span><span class="o">.</span><span class="n">nsym</span> <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">]))</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.__init__&quot;</span><span class="p">,</span><span class="s2">&quot;the number of symmetry type for symmetry bonds doesn&#39;t match.&quot;</span><span class="p">)</span>

            <span class="c1">## sort all BD_IN on first and BD_OUT on last:</span>
            <span class="c1">#lambda x: 1 if x.bondType is BD_OUT else 0</span>
            <span class="c1">#maper = np.argsort([ (x.bondType is BD_OUT) for x in self.bonds])</span>
            <span class="c1">#self.bonds = self.bonds[maper]</span>
            <span class="c1">#self.labels = self.labels[maper]</span>


        <span class="k">if</span> <span class="n">torch_tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>                
            <span class="k">else</span><span class="p">:</span>
                <span class="n">DALL</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">))]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">DALL</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span><span class="p">)</span>
                <span class="k">del</span> <span class="n">DALL</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch_tensor</span>
    
        <span class="k">if</span> <span class="n">requires_grad</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniTensor.SetLabel"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.SetLabel">[docs]</a>    <span class="k">def</span> <span class="nf">SetLabel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">newLabel</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set a new label for the bond local at specify index.</span>

<span class="sd">        Args:</span>

<span class="sd">            newLabel: The new label, it should be an integer.</span>

<span class="sd">            idx     : The index of the bond. when specified, the label of the bond at this index will be changed.</span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; a = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4)],labels=[5,6])</span>
<span class="sd">            &gt;&gt;&gt; a.labels</span>
<span class="sd">            [5 6]</span>


<span class="sd">            Set &quot;-1&quot; to replace the original label &quot;6&quot; at index 1</span>

<span class="sd">            &gt;&gt;&gt; a.SetLabel(-1,1)</span>
<span class="sd">            &gt;&gt;&gt; a.labels</span>
<span class="sd">            [5 -1]</span>
<span class="sd"> </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">newLabel</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetLabel&quot;</span><span class="p">,</span><span class="s2">&quot;newLabel and idx must be int.&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetLabel&quot;</span><span class="p">,</span><span class="s2">&quot;idx exceed the number of bonds.&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">newLabel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetLabel&quot;</span><span class="p">,</span><span class="s2">&quot;newLabel [</span><span class="si">%d</span><span class="s2">] already exists in the current UniTensor.&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">newLabel</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">newLabel</span></div>
    
<div class="viewcode-block" id="UniTensor.SetLabels"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.SetLabels">[docs]</a>    <span class="k">def</span> <span class="nf">SetLabels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">newlabels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set new labels for all the bonds.</span>

<span class="sd">        Args:</span>

<span class="sd">            newLabels: The list of new label, it should be an python list or numpy array with size equal to the number of bonds of the UniTensor.</span>
<span class="sd">                       </span>
<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; a = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4)],labels=[5,6])</span>
<span class="sd">            &gt;&gt;&gt; a.labels</span>
<span class="sd">            [5 6]</span>

<span class="sd">            Set new_label=[-1,-2] to replace the original label [5,6].</span>

<span class="sd">            &gt;&gt;&gt; new_label=[-1,-2]</span>
<span class="sd">            &gt;&gt;&gt; a.SetLabels(new_label)</span>
<span class="sd">            &gt;&gt;&gt; a.labels</span>
<span class="sd">            [-1 -2]</span>
<span class="sd"> </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">newlabels</span><span class="p">,</span><span class="nb">list</span><span class="p">):</span>
            <span class="n">newlabels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">newlabels</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">newlabels</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetLabels&quot;</span><span class="p">,</span><span class="s2">&quot;the length of newlabels not match with the rank of UniTensor&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">newlabels</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">newlabels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetLabels&quot;</span><span class="p">,</span><span class="s2">&quot;the newlabels contain duplicated elementes.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">newlabels</span><span class="p">)</span></div>

<div class="viewcode-block" id="UniTensor.SetElem"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.SetElem">[docs]</a>    <span class="k">def</span> <span class="nf">SetElem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">elem</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given 1D array of elements, set the elements stored in tensor as the same as the given ones. Note that elem can only be python-list or numpy </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            </span>
<span class="sd">            elem: </span>
<span class="sd">                The elements to be replace the content of the current UniTensor. It should be a 1D array.</span>
<span class="sd">                **Note** if the UniTensor is a symmetric tensor, one should use UniTensor.PutBlock to set the elements.</span>
<span class="sd"> </span>
<span class="sd">        Example:</span>
<span class="sd">        ::</span>
<span class="sd">            Sz = Tt.UniTensor(bonds=[Tt.Bond(Tt.BD_IN,2),Tt.Bond(Tt.BD_OUT,2)],</span>
<span class="sd">                              dtype=tor.float64,</span>
<span class="sd">                              device=tor.device(&quot;cpu&quot;))</span>
<span class="sd">            Sz.SetElem([1, 0,</span>
<span class="sd">                        0,-1 ])</span>

<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; print(Sz)</span>
<span class="sd">        Tensor name: </span>
<span class="sd">        is_diag    : False</span>
<span class="sd">        tensor([[ 1.,  0.],</span>
<span class="sd">                [ 0., -1.]], dtype=torch.float64)</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span><span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetElem&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR]  elem can only be python-list or numpy&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">numel</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetElem&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] number of elem is not equal to the # of elem in the tensor.&quot;</span><span class="p">)</span>
        
        <span class="c1">## Qnum_ipoint [OK]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.SetElem&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] the TN that has symm should use PutBlock.&quot;</span><span class="p">)</span>
        
        <span class="n">my_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">my_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">my_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">elem</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">my_type</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">my_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">my_device</span><span class="p">)</span></div>
        
<div class="viewcode-block" id="UniTensor.Todense"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Todense">[docs]</a>    <span class="k">def</span> <span class="nf">Todense</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the UniTensor to dense matrix. </span>
<span class="sd">            Currently only the diagonal matrix is stored as sparsed form. So it only has effect on UniTensor where is_diag = True</span>
<span class="sd">        </span>
<span class="sd">        Return:</span>
<span class="sd">            self</span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; a = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,3)],is_diag=True)</span>
<span class="sd">            &gt;&gt;&gt; print(a.is_diag)</span>
<span class="sd">            True</span>
<span class="sd">        </span>
<span class="sd">            </span>
<span class="sd">            &gt;&gt;&gt; a.Todense()</span>
<span class="sd">            &gt;&gt;&gt; print(a.is_diag)</span>
<span class="sd">            False</span>
<span class="sd">            </span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">=</span><span class="kc">False</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="UniTensor.to"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the UniTensor to device</span>

<span class="sd">        Args:</span>
<span class="sd">            </span>
<span class="sd">            device:</span>
<span class="sd">                This should be an [torch.device] </span>
<span class="sd">                torch.device(&quot;cpu&quot;) for put the tensor on host (cpu)</span>
<span class="sd">                torch.device(&quot;cuda:x&quot;) for put the tensor on GPU with index x</span>

<span class="sd">        Example:</span>

<span class="sd">            Construct a tensor (default is on cpu)</span>

<span class="sd">            &gt;&gt;&gt; a = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4)])</span>
<span class="sd">            </span>
<span class="sd">            Set to GPU.</span>

<span class="sd">            &gt;&gt;&gt; a.to(torch.device(&quot;cuda:0&quot;))</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;[ERROR] UniTensor.to()&quot;</span><span class="p">,</span><span class="s2">&quot;only support device argument in this version as torch.device&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>         </div>

    <span class="c1">## print layout:</span>
<div class="viewcode-block" id="UniTensor.Print_diagram"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Print_diagram">[docs]</a>    <span class="k">def</span> <span class="nf">Print_diagram</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is the beauty print of the tensor diagram. Including the information for the placeing device </span>
<span class="sd">        ::</span>
<span class="sd">            1.The left hand side is always the In-bond, and the right hand side is always the Out-bond. </span>
<span class="sd">            2.The number attach to the out-side of each leg is the Bond-dimension. </span>
<span class="sd">            3.The number attach to the in-side of each leg is the label. </span>
<span class="sd">            4.The real memory layout are follow clock-wise from upper-right to upper-left.</span>
<span class="sd">                          </span>

<span class="sd">            [ex:] Rank = 4. </span>
<span class="sd">            shape: (1,2,3,6) </span>
<span class="sd">            D_IN=[1,2], D_OUT=[3,6], labels=[0,5,3,11]</span>

<span class="sd">                        -----------</span>
<span class="sd">                   0  --| 1     3 |-- 3</span>
<span class="sd">                        |         |</span>
<span class="sd">                   5  --| 2     6 |-- 11</span>
<span class="sd">                        -----------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tensor Name : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tensor Rank : </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;on device   : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;is_diag     : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="s2">&quot;True&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="k">else</span> <span class="s2">&quot;False&quot;</span><span class="p">))</span>        
        
        <span class="n">Nin</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">))</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bondType</span> <span class="ow">is</span> <span class="n">BD_IN</span><span class="p">])</span>
        <span class="n">Nout</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">-</span> <span class="n">Nin</span>    
    
        <span class="k">if</span> <span class="n">Nin</span> <span class="o">&gt;</span> <span class="n">Nout</span><span class="p">:</span>
            <span class="n">vl</span> <span class="o">=</span> <span class="n">Nin</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vl</span> <span class="o">=</span> <span class="n">Nout</span>

        <span class="c1">#print(vl)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;        ---------------     &quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vl</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;        |             |     &quot;</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">&lt;</span><span class="n">Nin</span><span class="p">):</span>
                <span class="n">l</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%3d</span><span class="s2"> __&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">llbl</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%-3d</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span> 
            <span class="k">else</span><span class="p">:</span>
                <span class="n">l</span> <span class="o">=</span> <span class="s2">&quot;      &quot;</span>
                <span class="n">llbl</span> <span class="o">=</span> <span class="s2">&quot;   &quot;</span>
            <span class="k">if</span><span class="p">(</span><span class="n">i</span><span class="o">&lt;</span><span class="n">Nout</span><span class="p">):</span>
                <span class="n">r</span> <span class="o">=</span> <span class="s2">&quot;__ </span><span class="si">%-3d</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">Nin</span><span class="o">+</span><span class="n">i</span><span class="p">])</span>
                <span class="n">rlbl</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%3d</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">Nin</span><span class="o">+</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">r</span> <span class="o">=</span> <span class="s2">&quot;      &quot;</span>
                <span class="n">rlbl</span> <span class="o">=</span> <span class="s2">&quot;   &quot;</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  </span><span class="si">%s</span><span class="s2">| </span><span class="si">%s</span><span class="s2">     </span><span class="si">%s</span><span class="s2"> |</span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">llbl</span><span class="p">,</span><span class="n">rlbl</span><span class="p">,</span><span class="n">r</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;        |             |     &quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;        ---------------     &quot;</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lbl:</span><span class="si">%d</span><span class="s2"> &quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span></div>


        

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor name: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;is_diag    : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="s2">&quot;True&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="k">else</span> <span class="s2">&quot;False&quot;</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor name: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;is_diag    : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="s2">&quot;True&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="k">else</span> <span class="s2">&quot;False&quot;</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>

<div class="viewcode-block" id="UniTensor.__eq__"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.__eq__">[docs]</a>    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">rhs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Compare two UniTensor.</span>
<span class="sd">            ::</span>
<span class="sd">                a == b</span>

<span class="sd">            where a &amp; b are UniTensors.</span>

<span class="sd">            Note that this will only compare the shape of Storage. Not the content of torch tensor.</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rhs</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="n">iss</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">rhs</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">rhs</span><span class="o">.</span><span class="n">bonds</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">iss</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            
            <span class="n">iss</span> <span class="o">=</span> <span class="n">iss</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="n">rhs</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)))</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="n">rhs</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)))</span>
            <span class="k">return</span> <span class="n">iss</span>
                
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Bond.__eq__&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] invalid comparison between Bond object and other type class.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniTensor.shape"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.shape">[docs]</a>    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">            Return the shape of UniTensor</span>

<span class="sd">            Return:</span>
<span class="sd">                torch.Size object, using np.array() or list() to convert to numpy array and python list. </span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span></div>
    
    <span class="c1">## Fill :</span>
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">key</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">key</span><span class="p">,</span><span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
         

    <span class="c1">## Math ::</span>
    <span class="k">def</span> <span class="nf">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>\
                                <span class="n">is_diag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">False</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                    <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                    <span class="n">torch_tensor</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                    <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                    <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                    <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">),</span>\
                                    <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tmp</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                             <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                             <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+</span> <span class="n">other</span><span class="p">,</span>\
                             <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">is_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>\
                                <span class="n">is_diag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">False</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                 <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                 <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                 <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                    <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                    <span class="n">torch_tensor</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> <span class="o">-</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                    <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                    <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                    <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">),</span>\
                                    <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tmp</span>
        <span class="k">else</span> <span class="p">:</span>
            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                             <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                             <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-</span> <span class="n">other</span><span class="p">,</span>\
                             <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">is_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>\
                                <span class="n">is_diag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">False</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                 <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                 <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                 <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                    <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                    <span class="n">torch_tensor</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">,</span>\
                                    <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                                    <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                                    <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">),</span>\
                                    <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                            <span class="n">labels</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                            <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*</span> <span class="n">other</span><span class="p">,</span>\
                            <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>\
                            <span class="n">is_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tmp</span>

    <span class="k">def</span> <span class="nf">__pow__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">,</span>\
                         <span class="n">labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>\
                         <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">**</span><span class="n">other</span><span class="p">,</span>\
                         <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>\
                         <span class="n">is_diag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">__truediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_IN</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">D_OUT</span><span class="p">,</span>\
                             <span class="bp">self</span><span class="o">.</span><span class="n">Label_IN</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Label_OUT</span><span class="p">,</span>\
                             <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">/</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>
        <span class="k">else</span> <span class="p">:</span>
            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D_IN</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">D_OUT</span><span class="p">,</span>\
                             <span class="bp">self</span><span class="o">.</span><span class="n">Label_IN</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Label_OUT</span><span class="p">,</span>\
                             <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">/</span> <span class="n">other</span><span class="p">)</span>
    

    <span class="c1">## This is the same function that behaves as the memberfunction.</span>
<div class="viewcode-block" id="UniTensor.Svd"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Svd">[docs]</a>    <span class="k">def</span> <span class="nf">Svd</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> 
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">            This is the member function of Svd, see Tor10.linalg.Svd() </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">linalg</span><span class="o">.</span><span class="n">Svd</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

    <span class="c1">#def Svd_truncate(self):</span>
    <span class="c1">#    &quot;&quot;&quot; </span>
    <span class="c1">#        This is the member function of Svd_truncate, see Tor10.Svd_truncate() </span>
    <span class="c1">#    &quot;&quot;&quot;</span>
    <span class="c1">#    return Svd_truncate(self)</span>

<div class="viewcode-block" id="UniTensor.Norm"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Norm">[docs]</a>    <span class="k">def</span> <span class="nf">Norm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">            This is the member function of Norm, see Tor10.linalg.Norm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">linalg</span><span class="o">.</span><span class="n">Norm</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="UniTensor.Det"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Det">[docs]</a>    <span class="k">def</span> <span class="nf">Det</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">            This is the member function of Det, see Tor10.linalg.Det</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">linalg</span><span class="o">.</span><span class="n">Det</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="UniTensor.Matmul"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Matmul">[docs]</a>    <span class="k">def</span> <span class="nf">Matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">            This is the member function of Matmul, see Tor10.linalg.Matmul</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">linalg</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">b</span><span class="p">)</span></div>

    
    <span class="c1">## Extended Assignment:</span>
    <span class="k">def</span> <span class="nf">__iadd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>            
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+=</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">=</span><span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>

        <span class="k">else</span> <span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">+=</span> <span class="n">other</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">__isub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>            
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-=</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> <span class="o">+</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">=</span><span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>

        <span class="k">else</span> <span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">-=</span> <span class="n">other</span>
        <span class="k">return</span> <span class="bp">self</span>


    <span class="k">def</span> <span class="nf">__imul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>            
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*=</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span> <span class="o">*</span> <span class="n">other</span><span class="o">.</span><span class="n">Storage</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="o">=</span><span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>
        <span class="k">else</span> <span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">*=</span> <span class="n">other</span>
    
        <span class="k">return</span> <span class="bp">self</span>


    <span class="c1">## Miscellaneous</span>
<div class="viewcode-block" id="UniTensor.Rand"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Rand">[docs]</a>    <span class="k">def</span> <span class="nf">Rand</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Randomize the UniTensor.</span>

<span class="sd">            Note that in current version, only a UniTensor without symmetry quantum numbers can be randomized.</span>

<span class="sd">        Return: </span>
<span class="sd">            self</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_Randomize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1">## Qnum_ipoint</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;[Abort] UniTensor.Rand for symm TN is under developing&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="UniTensor.CombineBonds"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.CombineBonds">[docs]</a>    <span class="k">def</span> <span class="nf">CombineBonds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">labels_to_combine</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function combines the bonds in input UniTensor [a] by the specified labels [label].</span>
<span class="sd">    </span>
<span class="sd">        Args:</span>
<span class="sd">            </span>
<span class="sd">            labels_to_combine: </span>
<span class="sd">                labels that to be combined. It should be a int list / numpy array of the label. All the bonds with specified labels in the current UniTensor  will be combined</span>

<span class="sd">        Example:</span>

<span class="sd">            1. Combine Bond for an non-symmetric tensor.</span>

<span class="sd">            &gt;&gt;&gt; bds_x = [Tor10.Bond(Tor10.BD_IN,5),Tor10.Bond(Tor10.BD_OUT,5),Tor10.Bond(Tor10.BD_OUT,3)]</span>
<span class="sd">            &gt;&gt;&gt; x = Tor10.UniTensor(bonds=bds_x, labels=[4,3,5])</span>
<span class="sd">            &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 3</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">               4 __ | 5         5 |__ 3  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    |           3 |__ 5  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:4 Dim = 5 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:3 Dim = 5 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:5 Dim = 3 |</span>
<span class="sd">            OUT :</span>

<span class="sd">            &gt;&gt;&gt; x.CombineBonds([4,3])</span>
<span class="sd">            &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 2</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    |           3 |__ 5  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    |          25 |__ 3  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:5 Dim = 3 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:3 Dim = 25 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            _</span>

<span class="sd">            </span>
<span class="sd">            2. Combine bonds for a Symetric tensor.</span>

<span class="sd">                </span>



<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_CombineBonds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">labels_to_combine</span><span class="p">)</span></div>

<div class="viewcode-block" id="UniTensor.Contiguous"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">Contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make the memory to be contiguous. This is the same as pytorch&#39;s contiguous(). </span>
<span class="sd">        Because of the Permute does not move the memory, after permute, only the shape of UniTensor is changed, the underlying memory does not change. The UniTensor in this status is called &quot;non-contiguous&quot; tensor.</span>
<span class="sd">        When call the Contiguous(), the memory will be moved to match the shape of UniTensor. </span>
<span class="sd">        *Note* Normally, it is not nessary to call contiguous. Most of the linalg function implicity will make the UniTensor contiguous. If one calls a function that requires a contiguous tensor, the error will be issue. Then you know you have to put UniTensor.Contiguous() there.</span>

<span class="sd">        Return:</span>
<span class="sd">            self</span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; x = Tt.UniTensor(bonds=bds_x, labels=[4,3,5])</span>
<span class="sd">            &gt;&gt;&gt; print(x.is_contiguous())</span>
<span class="sd">            True</span>

<span class="sd">            &gt;&gt;&gt; x.Permute([0,2,1])  </span>
<span class="sd">            &gt;&gt;&gt; print(x.is_contiguous())</span>
<span class="sd">            False</span>

<span class="sd">            &gt;&gt;&gt; x.Contiguous()</span>
<span class="sd">            &gt;&gt;&gt; print(x.is_contiguous())</span>
<span class="sd">            True</span>
<span class="sd">            </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="UniTensor.is_contiguous"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.is_contiguous">[docs]</a>    <span class="k">def</span> <span class="nf">is_contiguous</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the status of memory contiguous.</span>

<span class="sd">        Return:</span>
<span class="sd">            bool, if True, then the Storage of UniTensor is contiguous. if False, then the Storage of UiTensor is non-contiguous. </span>
<span class="sd"> </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">()</span>        </div>


<div class="viewcode-block" id="UniTensor.Permute"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Permute">[docs]</a>    <span class="k">def</span> <span class="nf">Permute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">maper</span><span class="p">,</span><span class="n">N_inbond</span><span class="p">,</span><span class="n">by_label</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Permute the bonds of the UniTensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            maper:</span>
<span class="sd">                a python list with integer type elements that the UniTensor permute accroding to. </span>
<span class="sd">            </span>
<span class="sd">            N_inbond:</span>
<span class="sd">                The number of in-bond after permute.</span>

<span class="sd">            by_label:</span>
<span class="sd">                bool, when True, the maper using the labels. When False, the maper using the index.</span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; bds_x = [Tt.Bond(Tt.BD_IN,6),Tt.Bond(Tt.BD_OUT,5),Tt.Bond(Tt.BD_OUT,3)]</span>
<span class="sd">            &gt;&gt;&gt; x = Tt.UniTensor(bonds=bds_x, labels=[4,3,5])</span>
<span class="sd">            &gt;&gt;&gt; y = Tt.UniTensor(bonds=bds_x, labels=[4,3,5])</span>
<span class="sd">            &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 3</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">                4 __| 6         5 |__ 3  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    |           3 |__ 5  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:4 Dim = 6 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:3 Dim = 5 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:5 Dim = 3 |</span>
<span class="sd">            OUT :</span>

<span class="sd">            &gt;&gt;&gt; x.Permute([0,2,1],2)</span>
<span class="sd">            &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 3</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">                4 __| 6         5 |__ 3  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                5 __| 3           |      </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:4 Dim = 6 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:5 Dim = 3 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:3 Dim = 5 |</span>
<span class="sd">            OUT :</span>

<span class="sd">            &gt;&gt;&gt; y.Permute([3,4,5],2,by_label=True)</span>
<span class="sd">            &gt;&gt;&gt; y.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 3</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">                3 __| 5         3 |__ 5  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                4 __| 6           |      </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:3 Dim = 5 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:4 Dim = 6 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:5 Dim = 3 |</span>
<span class="sd">            OUT :</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.Permute&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] UniTensor.is_diag=True cannot be permuted.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">+</span>
                                                <span class="s2">&quot;[Suggest] Call UniTensor.Todense()&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">maper</span><span class="p">,</span><span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.Permute&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] maper should be an python list.&quot;</span><span class="p">)</span>            
 
       
        <span class="k">if</span> <span class="n">by_label</span><span class="p">:</span>
            <span class="c1">## check all label</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">lbl</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">maper</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.Permute&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] by_label=True but maper contain invalid labels not appear in the UniTensor label&quot;</span><span class="p">)</span>

            <span class="n">DD</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">))))</span>
            <span class="n">new_maper</span><span class="o">=</span><span class="p">[</span> <span class="n">DD</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">maper</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">new_maper</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">maper</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">new_maper</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1">## We don&#39;t need this. pytorch will handle the dimesion mismatch error.</span>
            <span class="c1">#if not len(maper) == len(self.labels):</span>
            <span class="c1">#    raise ValueError(&quot;UniTensor.Permute&quot;, &quot;[ERROR] len of maper should be the same as the rank of the UniTensor.&quot;)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">maper</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N_inbond</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">change</span><span class="p">(</span><span class="n">BD_IN</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">change</span><span class="p">(</span><span class="n">BD_OUT</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniTensor.Reshape"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.Reshape">[docs]</a>    <span class="k">def</span> <span class="nf">Reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">dimer</span><span class="p">,</span><span class="n">N_inbond</span><span class="p">,</span><span class="n">new_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reshape the UniTensor into the shape specified as [dimer], with the first [N_inbond] Bonds as in-bond and other bonds as out-bond. </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>

<span class="sd">            dimer:</span>
<span class="sd">                The new shape of the UniTensor. This should be a python list. </span>

<span class="sd">            N_inbond:</span>
<span class="sd">                The number of in-bond.</span>
<span class="sd">            </span>
<span class="sd">            new_labels:</span>
<span class="sd">                The new labels that will be set for new bonds after reshape. </span>

<span class="sd">        Example:</span>

<span class="sd">            &gt;&gt;&gt; bds_x = [Tt.Bond(Tt.BD_IN,6),Tt.Bond(Tt.BD_OUT,5),Tt.Bond(Tt.BD_OUT,3)]</span>
<span class="sd">            &gt;&gt;&gt; x = Tt.UniTensor(bonds=bds_x, labels=[4,3,5])</span>
<span class="sd">            &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 3</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">                4 __| 6         5 |__ 3  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    |           3 |__ 5  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:4 Dim = 6 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:3 Dim = 5 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:5 Dim = 3 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            </span>

<span class="sd">            &gt;&gt;&gt; x.Reshape([2,3,5,3],new_labels=[1,2,3,-1],N_inbond=2)</span>
<span class="sd">            &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 4</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">                1 __| 2         5 |__ 3  </span>
<span class="sd">                    |             |     </span>
<span class="sd">                2 __| 3         3 |__ -1 </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:1 Dim = 2 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:2 Dim = 3 |</span>
<span class="sd">            IN :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:3 Dim = 5 |</span>
<span class="sd">            OUT :</span>
<span class="sd">            _</span>
<span class="sd">            lbl:-1 Dim = 3 |</span>
<span class="sd">            OUT :</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.Reshape&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] UniTensor.is_diag=True cannot be Reshape.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">+</span>
                                                <span class="s2">&quot;[Suggest] Call UniTensor.Todense()&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dimer</span><span class="p">,</span><span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.Reshape&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] maper should be an python list.&quot;</span><span class="p">)</span>            

        <span class="c1">## Qnum_ipoint</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.Reshape&quot;</span><span class="p">,</span><span class="s2">&quot;[Abort] UniTensor with symm cannot be Reshape.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>


        <span class="c1">## This is not contiguous</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">dimer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dimer</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_labels</span><span class="p">)</span>

        <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span><span class="n">Nid</span><span class="p">,</span><span class="n">dim</span> <span class="p">:</span> <span class="n">Bond</span><span class="p">(</span><span class="n">BD_IN</span><span class="p">,</span><span class="n">dim</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">Nid</span> <span class="k">else</span> <span class="n">Bond</span><span class="p">(</span><span class="n">BD_OUT</span><span class="p">,</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">N_inbond</span><span class="p">,</span><span class="n">dimer</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dimer</span><span class="p">))])</span></div>



    <span class="c1">## Symmetric Tensor function</span>
<div class="viewcode-block" id="UniTensor.GetTotalQnums"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.GetTotalQnums">[docs]</a>    <span class="k">def</span> <span class="nf">GetTotalQnums</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return two combined bond objects that has the information for the total qnums at in and out bonds.</span>
<span class="sd">        </span>
<span class="sd">        Return:</span>
<span class="sd">            qnums_inbonds, qnums_outbonds:</span>

<span class="sd">            qnums_inbonds:</span>
<span class="sd">                a Tor10.Bond, the combined in-bond</span>
<span class="sd">            </span>
<span class="sd">            qnums_outbonds:</span>
<span class="sd">                a Tor10.Bond, the combined out-bond.</span>

<span class="sd">                </span>
<span class="sd">        Example:</span>

<span class="sd">            * Multiple Symmetry::</span>

<span class="sd">                ## multiple Qnum:</span>
<span class="sd">                ## U1 x U1 x Z2 x Z4</span>
<span class="sd">                ## U1 = {-2,-1,0,1,2}</span>
<span class="sd">                ## Z2 = {-1,1}</span>
<span class="sd">                ## Z4 = {0,1,2,3}</span>
<span class="sd">                bd_sym_1 = Tt.Bond(Tt.BD_IN,3,qnums=[[0, 2, 1, 0],</span>
<span class="sd">                                                     [1, 1,-1, 1],</span>
<span class="sd">                                                     [2,-1, 1, 0]])</span>
<span class="sd">                bd_sym_2 = Tt.Bond(Tt.BD_IN,4,qnums=[[-1, 0,-1, 3],</span>
<span class="sd">                                                     [ 0, 0,-1, 2],</span>
<span class="sd">                                                     [ 1, 0, 1, 0],</span>
<span class="sd">                                                     [ 2,-2,-1, 1]])</span>
<span class="sd">                bd_sym_3 = Tt.Bond(Tt.BD_OUT,2,qnums=[[-1,-2,-1,2],</span>
<span class="sd">                                                      [ 1, 1, -2,3]])</span>

<span class="sd">                sym_T = Tt.UniTensor(bonds=[bd_sym_1,bd_sym_2,bd_sym_3],labels=[1,2,3],dtype=tor.float64)</span>
<span class="sd">                </span>
<span class="sd">            &gt;&gt;&gt; tqin, tqout = sym_T.GetTotalQnums()</span>
<span class="sd">            &gt;&gt;&gt; print(tqin)</span>
<span class="sd">            Dim = 12 |</span>
<span class="sd">            IN  : -1 +0 +1 +2 +0 +1 +2 +3 +1 +2 +3 +4</span>
<span class="sd">                  +2 +2 +2 +0 +1 +1 +1 -1 -1 -1 -1 -3</span>
<span class="sd">                  +0 +0 +2 +0 -2 -2 +0 -2 +0 +0 +2 +0</span>
<span class="sd">                  +3 +2 +0 +1 +4 +3 +1 +2 +3 +2 +0 +1</span>

<span class="sd">            &gt;&gt;&gt; print(tqout)</span>
<span class="sd">            Dim = 2 |</span>
<span class="sd">            OUT : -1 +1</span>
<span class="sd">                  -2 +1</span>
<span class="sd">                  -1 -2</span>
<span class="sd">                  +2 +3</span>
<span class="sd">                </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetTotalQnums&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] GetTotal Qnums from a non-symm tensor&quot;</span><span class="p">)</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">bondType</span> <span class="ow">is</span> <span class="n">BD_OUT</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">])</span>
        <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
        <span class="n">tmp_bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
        <span class="n">tmp_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
        <span class="n">Nin</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="n">tmp</span><span class="o">==</span><span class="kc">False</span><span class="p">])</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">Nin</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Nin</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetTotalQnums&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] The TN symmetry structure is incorrect, without either any in-bond or any-outbond&quot;</span><span class="p">)</span>

        <span class="c1">#virtual_cb-in</span>
        <span class="n">cb_inbonds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">cb_inbonds</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">Nin</span><span class="p">])</span>

        <span class="n">cb_outbonds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="n">Nin</span><span class="p">])</span>
        <span class="n">cb_outbonds</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="n">Nin</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>

        <span class="k">return</span> <span class="n">cb_inbonds</span><span class="p">,</span><span class="n">cb_outbonds</span></div>


<div class="viewcode-block" id="UniTensor.PutBlock"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.PutBlock">[docs]</a>    <span class="k">def</span> <span class="nf">PutBlock</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">block</span><span class="p">,</span><span class="o">*</span><span class="n">qnum</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">## Note, block should be a numpy array.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> 
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;[Warning] PutBlock cannot be use for non-symmetry TN. Use SetElem instead.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">qnum</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">nsym</span> <span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.PutBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] The qnumtum numbers not match the number of type.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.PutBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Cannot put block on a diagonal tensor (is_diag=True)&quot;</span><span class="p">)</span>

            <span class="c1">## create a copy of bonds and labels information that has all the BD_IN on first.            </span>
            <span class="c1"># [IN, IN, ..., IN, IN, OUT, OUT, ..., OUT, OUT]</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">bondType</span> <span class="ow">is</span> <span class="n">BD_OUT</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">])</span>
            <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
            <span class="n">tmp_bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
            <span class="n">tmp_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
            <span class="n">Nin</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="n">tmp</span><span class="o">==</span><span class="kc">False</span><span class="p">])</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">Nin</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Nin</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.PutBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Trying to put a block on a TN without either any in-bond or any out-bond&quot;</span><span class="p">)</span>

            <span class="c1">#virtual_cb-in</span>
            <span class="n">cb_inbonds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">cb_inbonds</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">Nin</span><span class="p">])</span>
            <span class="n">i_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_inbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">nsym</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">i_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">i_in</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_inbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="n">n</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i_in</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.PutBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Trying to put a qnum block that is not exists in the total Qnum of in-bonds in current TN.&quot;</span><span class="p">)</span>

            <span class="c1">#virtual_cb_out            </span>
            <span class="n">cb_outbonds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="n">Nin</span><span class="p">])</span>
            <span class="n">cb_outbonds</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="n">Nin</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
            <span class="n">i_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_outbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">nsym</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">i_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">i_out</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_outbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="n">n</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i_out</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.PutBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Trying to put a qnum block that is not exists in the totoal Qnum out-bonds in current TN.&quot;</span><span class="p">)</span>
            
            <span class="n">rev_maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">maper</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">maper</span><span class="p">)</span>
            <span class="n">ori_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="c1">## this will copy a new tensor , future can provide an shallow copy with no new tensor will create, using .view() possibly handy for Getblock and change the element inplace.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">ori_shape</span><span class="p">[:</span><span class="n">Nin</span><span class="p">]),</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="c1">## no need to check if the size match. if the size doesn&#39;t match, let torch handle the error.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">i_in</span><span class="p">,</span><span class="n">i_out</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">block</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">i_in</span><span class="p">,</span><span class="n">i_out</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.PutBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] the block can only be an np.array or a </span><span class="si">%s</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="vm">__class__</span><span class="p">))</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">ori_shape</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">rev_maper</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="UniTensor.GetBlock"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.GetBlock">[docs]</a>    <span class="k">def</span> <span class="nf">GetBlock</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">*</span><span class="n">qnum</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the Block specify by the quantum number(s). If the UniTensor is non-symmetry, return self. </span>

<span class="sd">        Args:</span>
<span class="sd">            *qnum:</span>
<span class="sd">                The quantum number(s). Note that when get-block on a High-rank tensor, the quantum number represent the total quantum number of all the in(out)-bonds.</span>

<span class="sd">        Return:</span>
<span class="sd">            * UniTensor, rank-2 (for symmetry tensor)</span>
<span class="sd">            * self (only if the UniTensor is non-symmetry tensor)</span>
<span class="sd">        </span>
<span class="sd">        Example:</span>
<span class="sd">            * Single Symmetry::</span>
<span class="sd">                </span>
<span class="sd">                bd_sym_1 = Tt.Bond(Tt.BD_IN,3,qnums=[[0],[1],[2]])</span>
<span class="sd">                bd_sym_2 = Tt.Bond(Tt.BD_IN,4,qnums=[[-1],[2],[0],[2]])</span>
<span class="sd">                bd_sym_3 = Tt.Bond(Tt.BD_OUT,5,qnums=[[4],[2],[-1],[5],[1]])</span>
<span class="sd">                sym_T = Tt.UniTensor(bonds=[bd_sym_1,bd_sym_2,bd_sym_3],labels=[10,11,12],dtype=tor.float64)</span>
<span class="sd">                </span>
<span class="sd">            &gt;&gt;&gt; sym_T.Print_diagram()</span>
<span class="sd">            tensor Name : </span>
<span class="sd">            tensor Rank : 3</span>
<span class="sd">            on device   : cpu</span>
<span class="sd">            is_diag     : False</span>
<span class="sd">                    ---------------     </span>
<span class="sd">                    |             |     </span>
<span class="sd">               10 __| 3         5 |__ 12 </span>
<span class="sd">                    |             |     </span>
<span class="sd">               11 __| 4           |      </span>
<span class="sd">                    |             |     </span>
<span class="sd">                    ---------------     </span>
<span class="sd">            lbl:10 Dim = 3 |</span>
<span class="sd">            IN  : +0 +1 +2</span>
<span class="sd">            _</span>
<span class="sd">            lbl:11 Dim = 4 |</span>
<span class="sd">            IN  : -1 +2 +0 +2</span>
<span class="sd">            _</span>
<span class="sd">            lbl:12 Dim = 5 |</span>
<span class="sd">            OUT : +4 +2 -1 +5 +1</span>

<span class="sd">            &gt;&gt;&gt; q_in, q_out = GetTotalQnums()</span>
<span class="sd">            &gt;&gt;&gt; print(q_in)</span>
<span class="sd">            Dim = 12 |</span>
<span class="sd">            IN  : -1 +2 +0 +2 +0 +3 +1 +3 +1 +4 +2 +4</span>
<span class="sd">            </span>
<span class="sd">            &gt;&gt;&gt; print(q_out)</span>
<span class="sd">            Dim = 5 |</span>
<span class="sd">            OUT : +4 +2 -1 +5 +1</span>

<span class="sd">            &gt;&gt;&gt; block_2 = sym_T.GetBlock(2)</span>
<span class="sd">            &gt;&gt;&gt; print(block_2)</span>
<span class="sd">            Tensor name: </span>
<span class="sd">            is_diag    : False</span>
<span class="sd">            tensor([[0.],</span>
<span class="sd">                    [0.],</span>
<span class="sd">                    [0.]], dtype=torch.float64)</span>

<span class="sd">            </span>
<span class="sd">            * Multiple Symmetry::</span>

<span class="sd">                ## multiple Qnum:</span>
<span class="sd">                ## U1 x U1 x Z2 x Z4</span>
<span class="sd">                ## U1 = {-2,-1,0,1,2}</span>
<span class="sd">                ## Z2 = {-1,1}</span>
<span class="sd">                ## Z4 = {0,1,2,3}</span>
<span class="sd">                bd_sym_1 = Tt.Bond(Tt.BD_IN,3,qnums=[[0, 2, 1, 0],</span>
<span class="sd">                                                     [1, 1,-1, 1],</span>
<span class="sd">                                                     [2,-1, 1, 0]])</span>
<span class="sd">                bd_sym_2 = Tt.Bond(Tt.BD_IN,4,qnums=[[-1, 0,-1, 3],</span>
<span class="sd">                                                     [ 0, 0,-1, 2],</span>
<span class="sd">                                                     [ 1, 0, 1, 0],</span>
<span class="sd">                                                     [ 2,-2,-1, 1]])</span>
<span class="sd">                bd_sym_3 = Tt.Bond(Tt.BD_OUT,2,qnums=[[-1,-2,-1,2],</span>
<span class="sd">                                                      [ 1, 1, -2,3]])</span>

<span class="sd">                sym_T = Tt.UniTensor(bonds=[bd_sym_1,bd_sym_2,bd_sym_3],labels=[1,2,3],dtype=tor.float64)</span>
<span class="sd">                </span>
<span class="sd">            &gt;&gt;&gt; tqin, tqout = sym_T.GetTotalQnums()</span>
<span class="sd">            &gt;&gt;&gt; print(tqin)</span>
<span class="sd">            Dim = 12 |</span>
<span class="sd">            IN  : -1 +0 +1 +2 +0 +1 +2 +3 +1 +2 +3 +4</span>
<span class="sd">                  +2 +2 +2 +0 +1 +1 +1 -1 -1 -1 -1 -3</span>
<span class="sd">                  +0 +0 +2 +0 -2 -2 +0 -2 +0 +0 +2 +0</span>
<span class="sd">                  +3 +2 +0 +1 +4 +3 +1 +2 +3 +2 +0 +1</span>

<span class="sd">            &gt;&gt;&gt; print(tqout)</span>
<span class="sd">            Dim = 2 |</span>
<span class="sd">            OUT : -1 +1</span>
<span class="sd">                  -2 +1</span>
<span class="sd">                  -1 -2</span>
<span class="sd">                  +2 +3</span>

<span class="sd">            &gt;&gt;&gt; block_1123 = sym_T.GetBlock(1,1,-2,3)</span>
<span class="sd">            &gt;&gt;&gt; print(block_1123)</span>
<span class="sd">            Tensor name: </span>
<span class="sd">            is_diag    : False</span>
<span class="sd">            tensor([[0.]], dtype=torch.float64)</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Cannot get block on a diagonal tensor (is_diag=True)&quot;</span><span class="p">)</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[Warning] GetBlock a non-symmetry TN will return self regardless of qnum parameter pass in.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">qnum</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">nsym</span> <span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] The qnumtum numbers not match the number of type.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Cannot get block on a diagonal tensor (is_diag=True)&quot;</span><span class="p">)</span>
           
            
    
            <span class="c1">#######</span>
            <span class="c1">## create a copy of bonds and labels information that has all the BD_IN on first.            </span>
            <span class="c1"># [IN, IN, ..., IN, IN, OUT, OUT, ..., OUT, OUT]</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">bondType</span> <span class="ow">is</span> <span class="n">BD_OUT</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">])</span>
            <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
            <span class="n">tmp_bonds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
            <span class="n">tmp_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
            <span class="n">Nin</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="n">tmp</span><span class="o">==</span><span class="kc">False</span><span class="p">])</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">Nin</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Nin</span><span class="o">==</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Trying to get a block on a TN without either any in-bond or any out-bond&quot;</span><span class="p">)</span>

            <span class="c1">#virtual_cb-in</span>
            <span class="n">cb_inbonds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">cb_inbonds</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">Nin</span><span class="p">])</span>
            <span class="n">i_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_inbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">nsym</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">i_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">i_in</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_inbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="n">n</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i_in</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Trying to get a qnum block that is not exists in the total Qnum of in-bonds in current TN.&quot;</span><span class="p">)</span>

            <span class="c1">#virtual_cb_out            </span>
            <span class="n">cb_outbonds</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="n">Nin</span><span class="p">])</span>
            <span class="n">cb_outbonds</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">tmp_bonds</span><span class="p">[</span><span class="n">Nin</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
            <span class="n">i_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_outbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">nsym</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">i_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">i_out</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cb_outbonds</span><span class="o">.</span><span class="n">qnums</span><span class="p">[:,</span><span class="n">n</span><span class="p">]</span><span class="o">==</span><span class="n">qnum</span><span class="p">[</span><span class="n">n</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i_out</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.GetBlock&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Trying to get a qnum block that is not exists in the totoal Qnum out-bonds in current TN.&quot;</span><span class="p">)</span>
            
            <span class="c1">## virtual permute:</span>
            <span class="n">rev_maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">maper</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">maper</span><span class="p">)</span>
            <span class="n">ori_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span>

            <span class="c1">## this will copy a new tensor , future can provide an shallow copy with no new tensor will create, using .view() possibly handy for Getblock and change the element inplace.</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">ori_shape</span><span class="p">[:</span><span class="n">Nin</span><span class="p">]),</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">i_in</span><span class="p">,</span><span class="n">i_out</span><span class="p">)]</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">rev_maper</span><span class="p">)</span>

            <span class="c1">#print(out)</span>
            
            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span><span class="p">[</span><span class="n">Bond</span><span class="p">(</span><span class="n">BD_IN</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="n">Bond</span><span class="p">(</span><span class="n">BD_OUT</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>\
                             <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>\
                             <span class="n">torch_tensor</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>\
                             <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>
            

    <span class="c1">## Autograd feature: </span>
<div class="viewcode-block" id="UniTensor.requires_grad"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.requires_grad">[docs]</a>    <span class="k">def</span> <span class="nf">requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">is_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        The status for the autograd property.</span>

<span class="sd">        Args:</span>
<span class="sd">            is_grad: </span>
<span class="sd">                bool, if the autograd mechanism should be activate on this UniTensor. </span>
<span class="sd">                If the argument is not set, it will return the current autograd status. </span>
<span class="sd">                </span>
<span class="sd">        Return:</span>
<span class="sd">            bool, return only when is_grad argument is ignored. </span>

<span class="sd">        Example:</span>
<span class="sd">        ::</span>
<span class="sd">            bds_x = [Tt.Bond(Tt.BD_IN,5),Tt.Bond(Tt.BD_OUT,5),Tt.Bond(Tt.BD_OUT,3)]</span>
<span class="sd">            x = Tt.UniTensor(bonds=bds_x, labels=[4,3,5])</span>

<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; print(x.requires_grad())</span>
<span class="sd">        False</span>

<span class="sd">        &gt;&gt;&gt; x.requires_grad(True)</span>
<span class="sd">        &gt;&gt;&gt; print(x.requires_grad())</span>
<span class="sd">        True</span>

<span class="sd">        &gt;&gt;&gt; x.requires_grad(False)</span>
<span class="sd">        &gt;&gt;&gt; print(x.requires_grad())</span>
<span class="sd">        False</span>

<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">requires_grad</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="nb">bool</span><span class="p">(</span><span class="n">is_grad</span><span class="p">))</span></div>


<div class="viewcode-block" id="UniTensor.grad"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.grad">[docs]</a>    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the gradient tensors subject to x where x is the current UniTensor. The return is None by default and becomes a UniTensor the first time a call backward(). The future calls to backward() will accumulate (add) gradient into it.</span>

<span class="sd">        This is the same as torch.Tensor.grad</span>
<span class="sd">   </span>

<span class="sd">        :math:`d/dx`</span>

<span class="sd">        Return: </span>
<span class="sd">            UniTensor, the shape of the return UniTensor and it&#39;s bonds are the same as the original UniTensor, but with default labels.</span>

<span class="sd">        Example:</span>
<span class="sd">        </span>
<span class="sd">            &gt;&gt;&gt; x = Tor10.UniTensor(bonds=[Tor10.Bond(BD_IN,2),Tor10.Bond(BD_OUT,2)],requires_grad=True)</span>
<span class="sd">            &gt;&gt;&gt; print(x)</span>
<span class="sd">            Tensor name: </span>
<span class="sd">            is_diag    : False</span>
<span class="sd">            tensor([[0., 0.],</span>
<span class="sd">                    [0., 0.]], dtype=torch.float64, requires_grad=True)</span>

<span class="sd">            &gt;&gt;&gt; y = (x + 4)**2</span>
<span class="sd">            &gt;&gt;&gt; print(y)</span>
<span class="sd">            Tensor name: </span>
<span class="sd">            is_diag    : False</span>
<span class="sd">            tensor([[16., 16.],</span>
<span class="sd">                    [16., 16.]], dtype=torch.float64, grad_fn=&lt;PowBackward0&gt;)</span>

<span class="sd">            &gt;&gt;&gt; out = Tor10.Mean(y)</span>
<span class="sd">            &gt;&gt;&gt; print(out)</span>
<span class="sd">            Tensor name: </span>
<span class="sd">            is_diag    : False</span>
<span class="sd">            tensor(16., dtype=torch.float64, grad_fn=&lt;MeanBackward1&gt;)</span>

<span class="sd">            &gt;&gt;&gt; out.backward()</span>
<span class="sd">            &gt;&gt;&gt; print(x.grad)</span>
<span class="sd">            Tensor name: </span>
<span class="sd">            is_diag    : False</span>
<span class="sd">            tensor([[2., 2.],</span>
<span class="sd">                    [2., 2.]], dtype=torch.float64)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bonds</span><span class="p">),</span>\
                             <span class="n">torch_tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span>\
                             <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="UniTensor.backward"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.backward">[docs]</a>    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Backward the gradient flow in the contructed autograd graph. This is the same as torch.Tensor.backward</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span></div>


<div class="viewcode-block" id="UniTensor.detach"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.UniTensor.detach">[docs]</a>    <span class="k">def</span> <span class="nf">detach</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Detach the current tensor from the current graph, making it a leaf. This is the same as torch.Tensor.detach_()</span>

<span class="sd">        Return:</span>
<span class="sd">            self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>



<span class="c1">###############################################################</span>
<span class="c1">#</span>
<span class="c1"># Action function </span>
<span class="c1">#</span>
<span class="c1">##############################################################</span>
<span class="c1">## I/O</span>
<div class="viewcode-block" id="Save"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.Save">[docs]</a><span class="k">def</span> <span class="nf">Save</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save a UniTensor to the file</span>

<span class="sd">    Args:</span>
<span class="sd">        a: </span>
<span class="sd">            The UniTensor that to be saved.</span>
<span class="sd">        </span>
<span class="sd">        filename:</span>
<span class="sd">            The saved file path</span>

<span class="sd">    Example:</span>
<span class="sd">    ::</span>
<span class="sd">        a = Tor10.UniTensor(bonds=[Tor10.Bond(Tor10.BD_IN,3),Tor10.Bond(Tor10.BD_OUT,4)])</span>
<span class="sd">        Tor10.Save(a,&quot;a.uniT&quot;)</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="nb">str</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Save&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Invalid filename.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">UniTensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Save&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] input must be the UniTensor&quot;</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s2">&quot;wb&quot;</span><span class="p">)</span>
    <span class="n">pkl</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

<div class="viewcode-block" id="Load"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.Load">[docs]</a><span class="k">def</span> <span class="nf">Load</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a UniTensor from the file.</span>

<span class="sd">    Args:</span>
<span class="sd">        filename: </span>
<span class="sd">            The path of the file to be loaded</span>

<span class="sd">    Return:</span>
<span class="sd">        UniTensor</span>

<span class="sd">    Example:</span>
<span class="sd">    ::</span>
<span class="sd">        a = Tor10.Load(&quot;a.uniT&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="nb">str</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;UniTensor.Save&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] Invalid filename.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;UniTensor.Load&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] file not exists&quot;</span><span class="p">)</span>

    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">pkl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span><span class="n">UniTensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Load&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] loaded object is not the UniTensor&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tmp</span></div>

<div class="viewcode-block" id="Contract"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.Contract">[docs]</a><span class="k">def</span> <span class="nf">Contract</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">inbond_first</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contract two tensors with the same labels. </span>

<span class="sd">    1. two tensors must be the same type, if &quot;a&quot; is a symmetry tensor, &quot;b&quot; must also be a symmetry tensor.</span>
<span class="sd">    2. When contract two symmetry tensor, the bonds that to be contracted must have the same qnums.</span>

<span class="sd">    Args:</span>
<span class="sd">        a:</span>
<span class="sd">            UniTensor</span>

<span class="sd">        b:</span>
<span class="sd">            UniTensor</span>

<span class="sd">        inbond_first:</span>
<span class="sd">            bool</span>

<span class="sd">            * if True , the order of the bonds for the return tensor will be permuted to all the in-bond appears first, then the out-bond.</span>
<span class="sd">            * If False, the order of the bonds for the return tensor will have all the remaining bonds of tensor &quot;a&quot; appears first, then the remaining bonds of tensor &quot;b&quot;. </span>
<span class="sd">            * This is especially efficient in the case where the in/out bond are not important. By setting inbond_first=False, no additional permute will be perform at the last stage. </span>

<span class="sd">    Return:</span>
<span class="sd">        UniTensor</span>

<span class="sd">    Example:</span>
<span class="sd">    ::</span>
<span class="sd">        x = Tt.UniTensor(bonds=[Tt.Bond(Tt.BD_IN,5),Tt.Bond(Tt.BD_OUT,5),Tt.Bond(Tt.BD_OUT,4)], labels=[4,3,5])</span>
<span class="sd">        y = Tt.UniTensor(bonds=[Tt.Bond(Tt.BD_IN,3),Tt.Bond(Tt.BD_OUT,4)],labels=[1,5])</span>


<span class="sd">    &gt;&gt;&gt; x.Print_diagram()</span>
<span class="sd">    tensor Name : </span>
<span class="sd">    tensor Rank : 3</span>
<span class="sd">    on device   : cpu</span>
<span class="sd">    is_diag     : False</span>
<span class="sd">            ---------------     </span>
<span class="sd">            |             |     </span>
<span class="sd">        4 __| 5         5 |__ 3  </span>
<span class="sd">            |             |     </span>
<span class="sd">            |           4 |__ 5  </span>
<span class="sd">            |             |     </span>
<span class="sd">            ---------------     </span>
<span class="sd">    lbl:4 Dim = 5 |</span>
<span class="sd">    IN  :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:3 Dim = 5 |</span>
<span class="sd">    OUT :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:5 Dim = 4 |</span>
<span class="sd">    OUT :</span>

<span class="sd">    &gt;&gt;&gt; y.Print_diagram()</span>
<span class="sd">    tensor Name : </span>
<span class="sd">    tensor Rank : 2</span>
<span class="sd">    on device   : cpu</span>
<span class="sd">    is_diag     : False</span>
<span class="sd">            ---------------     </span>
<span class="sd">            |             |     </span>
<span class="sd">        1 __| 3         4 |__ 5  </span>
<span class="sd">            |             |     </span>
<span class="sd">            ---------------     </span>
<span class="sd">    lbl:1 Dim = 3 |</span>
<span class="sd">    IN  :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:5 Dim = 4 |</span>
<span class="sd">    OUT :</span>

<span class="sd">    &gt;&gt;&gt; c = Tt.Contract(x,y)</span>
<span class="sd">    &gt;&gt;&gt; c.Print_diagram()</span>
<span class="sd">    tensor Name : </span>
<span class="sd">    tensor Rank : 3</span>
<span class="sd">    on device   : cpu</span>
<span class="sd">    is_diag     : False</span>
<span class="sd">            ---------------     </span>
<span class="sd">            |             |     </span>
<span class="sd">        4 __| 5         5 |__ 3  </span>
<span class="sd">            |             |     </span>
<span class="sd">        1 __| 3           |      </span>
<span class="sd">            |             |     </span>
<span class="sd">            ---------------     </span>
<span class="sd">    lbl:4 Dim = 5 |</span>
<span class="sd">    IN  :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:1 Dim = 3 |</span>
<span class="sd">    IN  :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:3 Dim = 5 |</span>
<span class="sd">    OUT :</span>

<span class="sd">    &gt;&gt;&gt; c= Tt.Contract(x,y,inbond_first=False)</span>
<span class="sd">    &gt;&gt;&gt; c.Print_diagram()</span>
<span class="sd">    tensor Name : </span>
<span class="sd">    tensor Rank : 3</span>
<span class="sd">    on device   : cpu</span>
<span class="sd">    is_diag     : False</span>
<span class="sd">            ---------------     </span>
<span class="sd">            |             |     </span>
<span class="sd">        4 __| 5         3 |__ 1  </span>
<span class="sd">            |             |     </span>
<span class="sd">        3 __| 5           |      </span>
<span class="sd">            |             |     </span>
<span class="sd">            ---------------     </span>
<span class="sd">    lbl:4 Dim = 5 |</span>
<span class="sd">    IN  :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:3 Dim = 5 |</span>
<span class="sd">    OUT :</span>
<span class="sd">    _</span>
<span class="sd">    lbl:1 Dim = 3 |</span>
<span class="sd">    IN  :</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">UniTensor</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">UniTensor</span><span class="p">):</span>

        <span class="c1">## get same vector:</span>
        <span class="n">same</span><span class="p">,</span> <span class="n">a_ind</span><span class="p">,</span> <span class="n">b_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span><span class="n">b</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span><span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


        <span class="k">if</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">same</span><span class="p">)):</span>

            <span class="c1">## Qnum_ipoint</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span><span class="o">^</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Contract(a,b)&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] contract Symm TN with non-sym tensor&quot;</span><span class="p">)</span>

            <span class="k">if</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">qnums</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_ind</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">a_ind</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">qnums</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">b_ind</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">qnums</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Contact(a,b)&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] contract Bonds that has qnums mismatch.&quot;</span><span class="p">)</span>

            <span class="n">aind_no_combine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">)),</span><span class="n">a_ind</span><span class="p">)</span>
            <span class="n">bind_no_combine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">labels</span><span class="p">)),</span><span class="n">b_ind</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">is_diag</span> <span class="p">:</span>
                <span class="n">tmpa</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>   
                <span class="n">tmpa</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">Storage</span>
            
            <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">is_diag</span> <span class="p">:</span>
                <span class="n">tmpb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>   
                <span class="n">tmpb</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">Storage</span>

            <span class="n">tmp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">tmpa</span><span class="p">,</span><span class="n">tmpb</span><span class="p">,</span><span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="n">a_ind</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span><span class="n">b_ind</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            
            <span class="n">new_bonds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">aind_no_combine</span><span class="p">]),</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">bind_no_combine</span><span class="p">])])</span>
            
            <span class="n">new_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">aind_no_combine</span><span class="p">]),</span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">bind_no_combine</span><span class="p">])])</span>
            
            <span class="k">if</span> <span class="n">inbond_first</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_bonds</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                    <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">bondType</span><span class="o">==</span><span class="n">BD_OUT</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">new_bonds</span><span class="p">])</span>
                    <span class="n">new_bonds</span> <span class="o">=</span> <span class="n">new_bonds</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
                    <span class="n">new_labels</span><span class="o">=</span> <span class="n">new_labels</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">maper</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span> <span class="o">=</span><span class="n">new_bonds</span><span class="p">,</span>\
                             <span class="n">labels</span><span class="o">=</span><span class="n">new_labels</span><span class="p">,</span>\
                             <span class="n">torch_tensor</span><span class="o">=</span><span class="n">tmp</span><span class="p">,</span>\
                             <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1">## direct product</span>
            
            <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">is_diag</span> <span class="p">:</span>
                <span class="n">tmpa</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>   
                <span class="n">tmpa</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">Storage</span>
            
            <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">is_diag</span> <span class="p">:</span>
                <span class="n">tmpb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">Storage</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>   
                <span class="n">tmpb</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">Storage</span>

            <span class="n">tmp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">tmpa</span><span class="p">,</span><span class="n">tmpb</span><span class="p">,</span><span class="n">dims</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">new_bonds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">),</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">bonds</span><span class="p">)])</span>
            <span class="n">new_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">labels</span><span class="p">)])</span>

            <span class="k">if</span> <span class="n">inbond_first</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_bonds</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                    <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">bondType</span><span class="o">==</span><span class="n">BD_OUT</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">new_bonds</span><span class="p">])</span>
                    <span class="n">new_bonds</span> <span class="o">=</span> <span class="n">new_bonds</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
                    <span class="n">new_labels</span><span class="o">=</span> <span class="n">new_labels</span><span class="p">[</span><span class="n">maper</span><span class="p">]</span>
                    <span class="n">tmp</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="o">*</span><span class="n">maper</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span><span class="o">=</span><span class="n">new_bonds</span><span class="p">,</span>\
                             <span class="n">labels</span><span class="o">=</span><span class="n">new_labels</span><span class="p">,</span>\
                             <span class="n">torch_tensor</span><span class="o">=</span><span class="n">tmp</span><span class="p">,</span>\
                             <span class="n">check</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Contract(a,b)&#39;</span><span class="p">,</span> <span class="s2">&quot;[ERROR] a and b both have to be UniTensor&quot;</span><span class="p">)</span></div>


<span class="c1">#def Contract_old(a,b):</span>
<span class="c1">#    &quot;&quot;&quot;</span>
<span class="c1">#    &quot;&quot;&quot;</span>
<span class="c1">#    if isinstance(a,UniTensor) and isinstance(b,UniTensor):</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#        ## get same vector:</span>
<span class="c1">#        same, a_ind, b_ind = np.intersect1d(a.labels,b.labels,return_indices=True)</span>
<span class="c1">#</span>
<span class="c1">#        ## -v</span>
<span class="c1">#        #print(a_ind,b_ind)</span>
<span class="c1">#</span>
<span class="c1">#        if(len(same)):</span>
<span class="c1">#            ## check dim:</span>
<span class="c1">#            #for i in range(len(a_ind)):</span>
<span class="c1">#            #    if a.bonds[a_ind[i]].dim != b.bonds[b_ind[i]].dim:</span>
<span class="c1">#            #        raise ValueError(&quot;Contact(a,b)&quot;,&quot;[ERROR] contract Bonds that has different dim.&quot;)</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#            ## Qnum_ipoint</span>
<span class="c1">#            if (a.bonds[0].qnums is not None)^(b.bonds[0].qnums is not None):</span>
<span class="c1">#                raise Exception(&quot;Contract(a,b)&quot;,&quot;[ERROR] contract Symm TN with non-sym tensor&quot;)</span>
<span class="c1">#</span>
<span class="c1">#            if(a.bonds[0].qnums is not None):</span>
<span class="c1">#                for i in range(len(a_ind)):</span>
<span class="c1">#                    if not a.bonds[a_ind[i]].qnums.all() == b.bonds[b_ind[i]].qnums.all():</span>
<span class="c1">#                        raise ValueError(&quot;Contact(a,b)&quot;,&quot;[ERROR] contract Bonds that has qnums mismatch.&quot;)</span>
<span class="c1">#</span>
<span class="c1">#            aind_no_combine = np.setdiff1d(np.arange(len(a.labels)),a_ind)</span>
<span class="c1">#            bind_no_combine = np.setdiff1d(np.arange(len(b.labels)),b_ind)</span>
<span class="c1">#</span>
<span class="c1">#            #print(aind_no_combine,bind_no_combine)</span>
<span class="c1">#            </span>
<span class="c1">#            maper_a = np.concatenate([aind_no_combine,a_ind])</span>
<span class="c1">#            maper_b = np.concatenate([b_ind,bind_no_combine])</span>
<span class="c1">#</span>
<span class="c1">#            old_shape = np.array(a.Storage.shape) if a.is_diag==False else np.array([a.Storage.shape[0],a.Storage.shape[0]])</span>
<span class="c1">#            combined_dim = np.prod(old_shape[a_ind])</span>
<span class="c1">#</span>
<span class="c1">#            if a.is_diag :</span>
<span class="c1">#                tmpa = torch.diag(a.Storage).to(a.Storage.device)</span>
<span class="c1">#            else:   </span>
<span class="c1">#                tmpa = a.Storage</span>
<span class="c1">#            </span>
<span class="c1">#            if b.is_diag :</span>
<span class="c1">#                tmpb = torch.diag(b.Storage).to(b.Storage.device)</span>
<span class="c1">#            else:   </span>
<span class="c1">#                tmpb = b.Storage</span>
<span class="c1">#</span>
<span class="c1">#            tmp = torch.matmul(tmpa.permute(maper_a.tolist()).reshape(-1,combined_dim),\</span>
<span class="c1">#                               tmpb.permute(maper_b.tolist()).reshape(combined_dim,-1))</span>
<span class="c1">#            new_shape = [ bd.dim for bd in a.bonds[aind_no_combine]] + [ bd.dim for bd in b.bonds[bind_no_combine]]</span>
<span class="c1">#            return UniTensor(bonds =np.concatenate([a.bonds[aind_no_combine],b.bonds[bind_no_combine]]),\</span>
<span class="c1">#                             labels=np.concatenate([a.labels[aind_no_combine],b.labels[bind_no_combine]]),\</span>
<span class="c1">#                             torch_tensor=tmp.view(new_shape),\</span>
<span class="c1">#                             check=False)</span>
<span class="c1">#</span>
<span class="c1">#        else:</span>
<span class="c1">#            ## direct product</span>
<span class="c1">#            Nin_a = len([1 for i in range(len(a.labels)) if a.bonds[i].bondType is BD_IN])</span>
<span class="c1">#            Nin_b = len([1 for i in range(len(b.labels)) if b.bonds[i].bondType is BD_IN])</span>
<span class="c1">#            Nout_a = len(a.labels) - Nin_a</span>
<span class="c1">#            Nout_b = len(b.labels) - Nin_b</span>
<span class="c1">#</span>
<span class="c1">#            new_label = np.concatenate([a.labels, b.labels])</span>
<span class="c1">#            DALL = [a.bonds[i].dim for i in range(len(a.bonds))] + [b.bonds[i].dim for i in range(len(b.bonds))]</span>
<span class="c1">#</span>
<span class="c1">#            maper = np.concatenate([np.arange(Nin_a), len(a.labels) + np.arange(Nin_b), np.arange(Nout_a) + Nin_a, len(a.labels) + Nin_b + np.arange(Nout_b)])</span>
<span class="c1">#</span>
<span class="c1">#            if a.is_diag :</span>
<span class="c1">#                tmpa = torch.diag(a.Storage)</span>
<span class="c1">#            else:   </span>
<span class="c1">#                tmpa = a.Storage</span>
<span class="c1">#            </span>
<span class="c1">#            if b.is_diag :</span>
<span class="c1">#                tmpb = torch.diag(b.Storage)</span>
<span class="c1">#            else:   </span>
<span class="c1">#                tmpb = b.Storage</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#            return UniTensor(bonds=np.concatenate([a.bonds[:Nin_a],b.bonds[:Nin_b],a.bonds[Nin_a:],b.bonds[Nin_b:]]),\</span>
<span class="c1">#                            labels=np.concatenate([a.labels[:Nin_a], b.labels[:Nin_b], a.labels[Nin_a:], b.labels[Nin_b:]]),\</span>
<span class="c1">#                            torch_tensor=torch.ger(tmpa.view(-1),tmpb.view(-1)).reshape(DALL).permute(maper.tolist()),\</span>
<span class="c1">#                            check=False)</span>
<span class="c1">#            </span>
<span class="c1">#    else:</span>
<span class="c1">#        raise Exception(&#39;Contract(a,b)&#39;, &quot;[ERROR] a and b both have to be UniTensor&quot;)</span>





<span class="c1">## The functions that start with &quot;_&quot; are the private functions</span>

<span class="k">def</span> <span class="nf">_CombineBonds</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">label</span><span class="p">):</span>    
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function combines the bonds in input UniTensor [a] by the specified labels [label]. The bondType of the combined bonds will always follows the same bondType of bond in [a] with label of the first element in [label] </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        </span>
<span class="sd">        a: </span>
<span class="sd">            UniTensor</span>
<span class="sd">        </span>
<span class="sd">        label: </span>

<span class="sd">            labels that to be combined. It should be a int list / numpy array of the label. All the bonds with specified labels in the current UniTensor  will be combined</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">UniTensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">is_diag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;_CombineBonds&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] CombineBonds doesn&#39;t support diagonal matrix.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;_CombineBonds&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] the # of label_to_combine should be &lt;= rank of UniTensor&quot;</span><span class="p">)</span>
        <span class="c1"># checking :</span>
        <span class="n">same_lbls</span><span class="p">,</span> <span class="n">x_ind</span><span class="p">,</span> <span class="n">y_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span><span class="n">label</span><span class="p">,</span><span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1">#print(x_ind)</span>
        <span class="c1">#print(y_ind)</span>
        <span class="c1">#print(same_lbls)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">same_lbls</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;_CombineBonds&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR], label_to_combine doesn&#39;t exists in the UniTensor&quot;</span><span class="p">)</span>
        
        <span class="n">idx_no_combine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">)),</span><span class="n">x_ind</span><span class="p">)</span>
        <span class="n">old_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">combined_dim</span> <span class="o">=</span> <span class="n">old_shape</span><span class="p">[</span><span class="n">x_ind</span><span class="p">]</span>
        <span class="n">combined_dim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">combined_dim</span><span class="p">)</span>
        <span class="n">no_combine_dims</span> <span class="o">=</span> <span class="n">old_shape</span><span class="p">[</span><span class="n">idx_no_combine</span><span class="p">]</span>

        <span class="c1">## check if the combined bond will be in-bond or out-bond</span>
        <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">bondType</span> <span class="ow">is</span> <span class="n">BD_OUT</span><span class="p">:</span>        
            <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">idx_no_combine</span><span class="p">,</span><span class="n">x_ind</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_ind</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">1</span><span class="o">+</span><span class="n">i</span><span class="p">]])</span>
            <span class="n">a</span><span class="o">.</span><span class="n">bonds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">idx_no_combine</span><span class="p">],</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
            <span class="n">a</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx_no_combine</span><span class="p">],</span> <span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
            <span class="n">a</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">maper</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">no_combine_dims</span><span class="p">,</span><span class="n">combined_dim</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">maper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_ind</span><span class="p">,</span><span class="n">idx_no_combine</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_ind</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">combine</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">1</span><span class="o">+</span><span class="n">i</span><span class="p">]])</span>
            <span class="n">a</span><span class="o">.</span><span class="n">bonds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">a</span><span class="o">.</span><span class="n">bonds</span><span class="p">[</span><span class="n">idx_no_combine</span><span class="p">])</span>
            <span class="n">a</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">x_ind</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">a</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx_no_combine</span><span class="p">])</span>
            <span class="n">a</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">maper</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">combined_dim</span><span class="p">,</span><span class="n">no_combine_dims</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>





    <span class="k">else</span> <span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;_CombineBonds(UniTensor,int_arr)&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] )CombineBonds can only accept UniTensor&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_Randomize</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        @description: &lt;private function&gt; This function randomize a UniTensor.</span>
<span class="sd">        @params     : </span>
<span class="sd">                      a : UniTensor</span>
<span class="sd">        @return     : N/A </span>
<span class="sd">                    </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">UniTensor</span><span class="p">):</span>
    
        <span class="n">a</span><span class="o">.</span><span class="n">Storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">Storage</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    
        
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;_Randomize(UniTensor)&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] _Randomize can only accept UniTensor&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="From_torch"><a class="viewcode-back" href="../../UniTensor.html#Tor10.UniTensor.From_torch">[docs]</a><span class="k">def</span> <span class="nf">From_torch</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">,</span><span class="n">N_inbond</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">    Construct UniTensor from torch.Tensor. </span>
<span class="sd">    </span>
<span class="sd">    If the input torch_tensor belongs to a autograd graph, the contructed UniTensor will preserve the role of the input torch_tensor in the computational graph.</span>

<span class="sd">    Args:</span>
<span class="sd">        torch_tensor:</span>
<span class="sd">            Torch.Tensor</span>
<span class="sd">    </span>
<span class="sd">        N_inbond:</span>
<span class="sd">            int, The number of inbond. Note that the first [N_inbond] bonds will be set to Tor10.BD_IN, and the remaining bonds will be set to Tor10.BD_OUT</span>
<span class="sd">        </span>
<span class="sd">        labels:</span>
<span class="sd">            python list or 1d numpy array, The labels for each bonds. If ignore, the constucted UniTensor will using the default labels for each bond.</span>

<span class="sd">    Return:</span>
<span class="sd">        UniTensor</span>

<span class="sd">    Example:</span>
<span class="sd">    </span>
<span class="sd">        &gt;&gt;&gt; x = torch.ones(3,3)</span>
<span class="sd">        &gt;&gt;&gt; print(x)</span>
<span class="sd">        tensor([[1., 1., 1.],</span>
<span class="sd">                [1., 1., 1.],</span>
<span class="sd">                [1., 1., 1.]])</span>

<span class="sd">        &gt;&gt;&gt; y = Tt.From_torch(x,N_inbond=1,labels=[4,5])</span>
<span class="sd">        &gt;&gt;&gt; y.Print_diagram()</span>
<span class="sd">        tensor Name : </span>
<span class="sd">        tensor Rank : 2</span>
<span class="sd">        on device   : cpu</span>
<span class="sd">        is_diag     : False</span>
<span class="sd">                ---------------     </span>
<span class="sd">                |             |     </span>
<span class="sd">            4 __| 3         3 |__ 5  </span>
<span class="sd">                |             |     </span>
<span class="sd">                ---------------     </span>
<span class="sd">        lbl:4 Dim = 3 |</span>
<span class="sd">        IN  :</span>
<span class="sd">        _</span>
<span class="sd">        lbl:5 Dim = 3 |</span>
<span class="sd">        OUT :</span>

<span class="sd">        &gt;&gt;&gt; print(y)</span>
<span class="sd">        Tensor name: </span>
<span class="sd">        is_diag    : False</span>
<span class="sd">        tensor([[1., 1., 1.],</span>
<span class="sd">                [1., 1., 1.],</span>
<span class="sd">                [1., 1., 1.]])</span>


<span class="sd">        &gt;&gt;&gt; x2 = torch.ones(3,4,requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; print(x2)</span>
<span class="sd">        tensor([[1., 1., 1., 1.],</span>
<span class="sd">                [1., 1., 1., 1.],</span>
<span class="sd">                [1., 1., 1., 1.]], requires_grad=True)</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; y2 = Tt.From_torch(x2,N_inbond=1)</span>
<span class="sd">        &gt;&gt;&gt; print(y2.requires_grad())</span>
<span class="sd">        True</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;From_torch&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] can only accept torch.Tensor&quot;</span><span class="p">)</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">torch_tensor</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="k">if</span> <span class="n">N_inbond</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;From_torch&quot;</span><span class="p">,</span><span class="s2">&quot;[ERROR] N_inbond exceed the rank of input torch tensor.&quot;</span><span class="p">)</span>

    <span class="n">new_bonds</span> <span class="o">=</span> <span class="p">[</span><span class="n">Bond</span><span class="p">(</span><span class="n">BD_IN</span><span class="p">,</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_inbond</span><span class="p">)]</span><span class="o">+</span>\
                <span class="p">[</span><span class="n">Bond</span><span class="p">(</span><span class="n">BD_OUT</span><span class="p">,</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_inbond</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span><span class="mi">1</span><span class="p">)]</span>


    <span class="k">return</span> <span class="n">UniTensor</span><span class="p">(</span><span class="n">bonds</span><span class="o">=</span><span class="n">new_bonds</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span><span class="n">torch_tensor</span><span class="o">=</span><span class="n">torch_tensor</span><span class="p">)</span></div>




</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Kai-Hsin Wu

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>